{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "23/10/12 20:52:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\r\n",
    "from pyspark.sql.functions import to_json,col\r\n",
    "from pyspark.sql.types import *\r\n",
    "from os.path import abspath\r\n",
    "\r\n",
    "spark = SparkSession\\\r\n",
    "        .builder\\\r\n",
    "        .appName(\"pyspark-notebook\")\\\r\n",
    "        .master(\"spark://spark-master:7077\")\\\r\n",
    "        .config(\"spark.executor.memory\", \"512m\")\\\r\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\")\\\r\n",
    "        .config(\"spark.sql.warehouse.dir\", \"/user/hive/warehouse\")\\\r\n",
    "        .enableHiveSupport()\\\r\n",
    "        .getOrCreate()\r\n",
    "\r\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libpcre2-8-0\n",
      "The following NEW packages will be installed:\n",
      "  libpcre2-8-0 wget\n",
      "0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 1115 kB of archives.\n",
      "After this operation, 3925 kB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 libpcre2-8-0 amd64 10.32-5 [213 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 wget amd64 1.20.1-1.1 [902 kB]\n",
      "Fetched 1115 kB in 1s (2034 kB/s)\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package libpcre2-8-0:amd64.\n",
      "(Reading database ... 27731 files and directories currently installed.)\n",
      "Preparing to unpack .../libpcre2-8-0_10.32-5_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking libpcre2-8-0:amd64 (10.32-5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package wget.\n",
      "Preparing to unpack .../wget_1.20.1-1.1_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking wget (1.20.1-1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up libpcre2-8-0:amd64 (10.32-5) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up wget (1.20.1-1.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Processing triggers for libc-bin (2.28-10) ...\n",
      "\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "!apt install wget -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-10-12 21:00:02--  https://drive.google.com/uc?export=download&id=1wdytBkoYRyaNNv3XUNnwcGbdNUSfok7u\n",
      "Resolving drive.google.com (drive.google.com)... 64.233.165.194, 2a00:1450:4010:c07::c2\n",
      "Connecting to drive.google.com (drive.google.com)|64.233.165.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://doc-0c-c0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hq6bruqkegk5tburup1p8u8phqksmplp/1697144400000/14904333240138417226/*/1wdytBkoYRyaNNv3XUNnwcGbdNUSfok7u?e=download&uuid=8924b671-6f93-4378-9805-1f405a280e95 [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2023-10-12 21:00:03--  https://doc-0c-c0-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/hq6bruqkegk5tburup1p8u8phqksmplp/1697144400000/14904333240138417226/*/1wdytBkoYRyaNNv3XUNnwcGbdNUSfok7u?e=download&uuid=8924b671-6f93-4378-9805-1f405a280e95\n",
      "Resolving doc-0c-c0-docs.googleusercontent.com (doc-0c-c0-docs.googleusercontent.com)... 216.58.211.225, 216.58.209.193, 2a00:1450:4026:802::2001\n",
      "Connecting to doc-0c-c0-docs.googleusercontent.com (doc-0c-c0-docs.googleusercontent.com)|216.58.211.225|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8886971 (8.5M) [application/zip]\n",
      "Saving to: ‘uplift_data.zip’\n",
      "\n",
      "uplift_data.zip     100%[===================>]   8.47M  8.55MB/s    in 1.0s    \n",
      "\n",
      "2023-10-12 21:00:04 (8.55 MB/s) - ‘uplift_data.zip’ saved [8886971/8886971]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://drive.google.com/uc?export=download&id=1wdytBkoYRyaNNv3XUNnwcGbdNUSfok7u' -O uplift_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  uplift_data.zip\n",
      "  inflating: clients.csv             \n",
      "  inflating: uplift_test.csv         \n",
      "  inflating: uplift_train.csv        \n"
     ]
    }
   ],
   "source": [
    "!unzip uplift_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " clients.csv                                                  uplift_data.zip\n",
      " pyspark.ipynb                                                uplift_test.csv\n",
      "'uc?export=download&id=1wdytBkoYRyaNNv3XUNnwcGbdNUSfok7u'     uplift_train.csv\n",
      "'uc?export=download&id=1wdytBkoYRyaNNv3XUNnwcGbdNUSfok7u.1'\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(path=\"clients.csv\", sep=\",\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400162"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(client_id='000012768d', first_issue_date='2017-08-05 15:40:48', first_redeem_date='2018-01-04 19:30:07', age='45', gender='U')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.select([\"client_id\", \"age\", \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(client_id='000012768d', age='45', gender='U')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data.select([\"client_id\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_description = df1.filter(df1['age'] == '45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.join(other=cols_description, on=['age'], how='left_anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumnRenamed(\"client_id\", \"c1\").withColumnRenamed(\"age\", \"c2\").withColumnRenamed(\"gender\", \"c3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1.write.saveAsTable('hive_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf= spark.sql(\"\"\"\r\n",
    "select * from hive_table\r\n",
    "\"\"\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| c2|        c1|\n",
      "+---+----------+\n",
      "| 72|000036f903|\n",
      "| 68|000048b7a6|\n",
      "| 60|000073194a|\n",
      "| 67|00007c7133|\n",
      "| 46|0000b59cec|\n",
      "| 36|0000bb4e4e|\n",
      "| 34|0000bcec9c|\n",
      "| 70|0000eecb82|\n",
      "| 56|0000f0ecdb|\n",
      "| 83|00010925a5|\n",
      "+---+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ndf.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
